{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of sugar content of menu items at various restaurants\n",
    "\n",
    "This project fundamentally relies on data from the [Nutritionix API](http://www.nutritionix.com/api). I am very grateful for the use of their data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import minimum_sugar\n",
    "\n",
    "# Load credential data from file\n",
    "with open(\"credentials.json\", \"r\") as f:\n",
    "    credentials = json.load(f)\n",
    "    \n",
    "# Load menu data from file\n",
    "with open(\"menu_data.json\", \"r\") as f:\n",
    "    menu_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restaurant IDs\n",
    "Nutritionix identifies restaurants by a unique number, but from what I can tell they do not list those numbers. The code in this section creates a mapping between the names of restaurants I frequent and Nutritionix's restaurant ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "restaurant_names = [\"McDonald's\",\n",
    "                    \"Wendy's\",\n",
    "                    \"Taco Bell\",\n",
    "                    \"Qdoba\",\n",
    "                    \"Chipotle\",\n",
    "                    \"Five Guys\",]\n",
    "                    #\"Costco\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurant_ids = [minimum_sugar.fetch_restaurant_id(name, credentials) for name in restaurant_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the data to a file for reading at a later date.\n",
    "# with open(\"restaurant_ids.json\", \"w\") as f:\n",
    "#     f.write(json.dumps(restaurant_ids, indent=4, separators=(',', ': ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restaurant menus\n",
    "Download restaurant menu nutrition data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fetch menu data and add to each dict in `restaurant_ids`\n",
    "# for restaurant in restaurant_ids:\n",
    "#     restaurant[\"menu\"] = minimum_sugar.fetch_menu_item_data(restaurant[\"id\"], credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Could do some list comprehension here, but I think it code readability would suffer.\n",
    "menu_data = []\n",
    "for restaurant in restaurant_ids:\n",
    "    menu_data.extend(minimum_sugar.fetch_menu_item_data(restaurant[\"id\"], credentials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write the data to a file for future analysis\n",
    "# with open(\"menu_data.json\", \"w\") as f:\n",
    "#     f.write(json.dumps(menu_data, indent=4, separators=(',', ': ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorizing menu items\n",
    "It turns out that the menu items of these various restaurants are not categoriezed according to any universal scheme (e.g. beverage, condiment, etc.). Moreover, some restaurants (like McDonald's) list beverages on their menu whereas others (e.g. Chipotle) do not. Beverages really skew the sugar content of the histogram, and the data I really wanted was simply the sugar content of the entree items.\n",
    "\n",
    "I ended up categorizing the menu items partially by hand. Some of the intermediate details can be found in `menu_item_categorization.ipynb`. The goal was to categorize menu items according to the following categories:\n",
    "\n",
    "* beverage\n",
    "* dessert\n",
    "* condiment\n",
    "* side order\n",
    "* entree\n",
    "\n",
    "The overall workflow was to first create a list of `item_name`s from the list of menu item data. The `item_names` list was written to a file (`item_names.dat`) with one `item_name` per line. I started with category \"beverage\" and deleted everything from the `item_names.dat` file that looked like it was a drink. I then used the remainder and the original `item_names` list to create python `set` objects and recover the list of beverage item names. The following code is an example of the process (not exactly what happened, but captures the essence):\n",
    "\n",
    "```python\n",
    "# Remove beverage item names from the `item_names.dat` file by hand.\n",
    "\n",
    "# Bring the result back into memory.\n",
    "with open(\"item_names.dat\", \"r\") as f:\n",
    "    remainder = [line.strip() for line in f]\n",
    "\n",
    "item_names_set = set(item_names)\n",
    "remainder_set = set(remainder)\n",
    "\n",
    "beverage_item_names_set = item_names_set - remainder_set\n",
    "beverage_item_names = list(beverage_item_names_set)\n",
    "beverage_item_names.sort()\n",
    "\n",
    "with open(\"beverage_item_names.json\", \"w\") as f:\n",
    "    f.write(json.dumps(beverage_item_names, indent=4, separators=(',', ': ')))\n",
    "```\n",
    "\n",
    "I repeated this process of elimination to generate lists of menu items according to each category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the \"database\" with `menu_category` field and check results\n",
    "Once this process was completed, I had several files of item names; each file contained the items of a particular category. For maximum utility, these categories should be included in the makeshift database in `menu_data.json`. Once the `menu_category` field is populated for each item in the `menu_data.json` list, I can write some simple code to check my categorization, broken down by each restaurant.\n",
    "\n",
    "The code to check the categorization and update `menu_data.json` is as follows:\n",
    "\n",
    "```python\n",
    "categories = [\"beverage\",\n",
    "    \"dessert\",\n",
    "    \"condiment\",\n",
    "    \"side\",\n",
    "    \"entree\",]\n",
    "\n",
    "categorized_item_names = {}\n",
    "\n",
    "for category in categories:\n",
    "    filename = category + \"_item_names.json\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        item_names = json.load(f)\n",
    "\n",
    "    categorized_items = {item_name: category for item_name in item_names}\n",
    "    categorized_item_names.update(categorized_items)\n",
    "    \n",
    "# Check that items weren't dropped during categorization.\n",
    "# The best way to do this check is to create two sets:\n",
    "# One set of all of the menu item names in `menu_data`.\n",
    "# The other set from the keys of `categorized_item_names`.\n",
    "# I can then use set operations to compare these two sets.\n",
    "\n",
    "assert set(minimum_sugar.extract_variable(menu_data, \"item_name\")) == set(categorized_item_names.keys())\n",
    "\n",
    "# Categorize each menu item in `menu_data` by adding \n",
    "# the \"menu_category\" field and data from above.\n",
    "for item in menu_data:\n",
    "    # I could fold the following line into the set operation on the `item` dict, \n",
    "    # but I'm separating the operations for the sake of code readability.\n",
    "    item_name = item[\"item_name\"]\n",
    "    item[\"menu_category\"] = categorized_item_names[item_name]\n",
    "    \n",
    "# Reformat data into a dict so I'm not viewing superfluous data and so that I can categorize\n",
    "# according to restaurant and menu category.\n",
    "categorized_item_names = {}\n",
    "\n",
    "for restaurant_name in restaurant_names:\n",
    "    restaurant_menu_data = minimum_sugar.filter_menu_items(menu_data, \"brand_name\", restaurant_name)\n",
    "\n",
    "    subdict = {}\n",
    "    for category in categories:\n",
    "        restaurant_categorized_menu_items = minimum_sugar.filter_menu_items(restaurant_menu_data, \"menu_category\", category)\n",
    "        restr_categ_menu_item_names = minimum_sugar.extract_variable(restaurant_categorized_menu_items, \"item_name\")\n",
    "        restr_categ_menu_item_names.sort()\n",
    "\n",
    "        subdict[category] = restr_categ_menu_item_names\n",
    "\n",
    "    categorized_item_names[restaurant_name] = subdict\n",
    "    \n",
    "# Print the result to check categorization\n",
    "print json.dumps(categorized_item_names, indent=4, separators=(',', ': '))\n",
    "\n",
    "# Everything is categorized properly, save the result.\n",
    "with open(\"menu_data.json\", \"w\") as f:\n",
    "    f.write(json.dumps(menu_data, indent=4, separators=(',', ': ')))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# for restaurant_name in restaurant_names:\n",
    "#     restaurant_menu_items = minimum_sugar.filter_menu_items(menu_data, \"brand_name\", restaurant_name)\n",
    "#     restaurant_entree_items = minimum_sugar.filter_menu_items(restaurant_menu_items, \"menu_category\", \"entree\")\n",
    "#     f = minimum_sugar.menu_histogram(restaurant_entree_items, \"nf_sugars\", title=restaurant_name, param_name=\"Sugar [g]\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Misc. observations during development\n",
    "This section contains some notes on observations I made during development. I intend to include these observations in the report, but rewritten into the body itself and not this section.\n",
    "\n",
    "First, the legacy/non-fast casual restaurants have a **ton** of menu items. McDonald's has >350 where Chipotle only has like 25. I can't imagine the amout of complexity that number of menu items adds to the management of the company. I also can't see how McDonalds gets rid of this complexity (i.e. sheds menu items) without alienating the customers these items intended to serve. It seems like this amount of complexity is an accretion over many years and is likely a result of their success. It seems eminently plausible that over the years executives at McDonalds thought, \"We are dominating this part of the market which is basically tapped out. In order to experience even more growth, we need to expand into other markets. How do we expand into other markets while leveraging the power of this brand to crush the competition?\"\n",
    "\n",
    "Second, executing this project has made me vaguely aware that some of my development practices may not be suited for data science projects. For example, I think the workflow I am using to perform this analysis may not be the most effective. The workflow is: download all data from the server, then write filtering code to eventually get the data I want. I feel like some incarnation of this workflow is what a seasoned data scientist might do, but I suspect most of the filtering will be done by the server or at the database as opposed to at the level of the data scientists local machine.\n",
    "\n",
    "As of commit [e297afb9](https://github.com/jrsmith3/minimum_sugar/commit/e297afb990153e07a80e8442aedcd4babb6b458b), I switched to a flat data structure. I thought this approach was going to make things easier, but I didn't realize how much easier it made things. I now just consider the menu item data to be a big pile of data, and I let the computer extract what I need based on queries I submit. I suspect this situation is how things are when one has a well-constructed database. Based on this experience, I should learn how to use SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
